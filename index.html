
<!DOCTYPE html>
<html>
  <!-- 基本模板与网站标题 -->
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>
      Towards Geometric and Textural Consistency 3D Scene Generation via Single Image-guided Model Generation and Layout Optimization
    </title>

    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet" />

    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
    <link rel="stylesheet" href="./static/css/index.css" />
    <!-- <link rel="icon" href="./static/images/favicon.svg" /> -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three/examples/js/loaders/GLTFLoader.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three/examples/js/controls/OrbitControls.js"></script>
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/swiper@8/swiper-bundle.min.css" />
    <script src="https://cdn.jsdelivr.net/npm/swiper@8/swiper-bundle.min.js"></script>

    <!--  Scene Viewer -->
    <link rel="stylesheet" href="modules/SceneViewer/scene-viewer.css" />

    <!-- Video Viewer -->
    <link rel="stylesheet" href="modules/VideoViewer/video-viewer.css" />
  </head>

  <body>
    <!-- 其他工作 -->
    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a
          role="button"
          class="navbar-burger"
          aria-label="menu"
          aria-expanded="false">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>

      <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center">
          <a class="navbar-item" href="https://github.com/xdlbw">
            <span class="icon">
              <i class="fas fa-home"></i>
            </span>
          </a>
        </div>
      </div>
    </nav>

    <!-- 标题，作者，友链 -->
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title" style="
                  font-size: clamp(1.9rem, 4.2vw, 2.6rem); /* 微调字号适配三行布局 */
                  background: linear-gradient(135deg, #7b1fa2 #9c27b0,  #e91e63, #ff9a9e);
                  -webkit-background-clip: text;
                  background-clip: text;
                  color: transparent;
                  line-height: 1.25;
                  max-width: 920px; /* 扩大最大宽度避免挤压换行 */
                  margin: 0 auto;
                  white-space: nowrap; /* 防止自动拆分单词 */
                ">
                Towards Geometric and Textural Consistency 3D Scene Generation via Single Image-guided Model Generation and Layout Optimization
              </h1>
              <div class="is-size-5 publication-authors">
                <a
                  target="_blank"
                  >Xiang Tang</a
                ><sup>1</sup>,
                <a
                  href="https://scholar.google.com/citations?user=4LsZhDgAAAAJ"
                  target="_blank"
                  >Xiaopeng Fan</a
                ><sup>2</sup>,
                <a
                  href="https://scholar.google.com/citations?user=6zC1cbgAAAAJ"
                  target="_blank"
                  >Ruotong Li</a
                ><sup>3✉</sup>,
              </div>

              <div class="is-size-5 publication-authors">
                <sup>1</sup>Harbin Institute of Technology, Shenzhen &nbsp;&nbsp; <sup>2</sup>Harbin Institute of Technology
                &nbsp;&nbsp; <sup>3</sup>Pengcheng Laboratory <br />
                <sup>✉</sup>Corresponding
                Author
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- PDF Link. -->
                  <span class="link-block">
                    <a
                      href=""
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>
                  <!-- Video Link. -->
                  <!-- <span class="link-block">
                    <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                       class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                          <i class="fab fa-youtube"></i>
                      </span>
                      <span>Video</span>
                    </a>
                  </span> -->
                  <!-- Code Link. -->
                  <span class="link-block">
                    <a
                      href="https://github.com/xdlbw/sing3d"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>
                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a 
                      href="" 
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                </div>
              </div>

              <div class="is-size-5 publication-authors">
                <hr
                  style="
                    width: 100%;
                    height: 0.7px;
                    background-color: rgba(0, 0, 0, 0.665);
                    margin-top: 1em;
                  " />
                Create high-fidelity 3D Scene from a single image.
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- 第一段图片与视频展示部分 -->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <img src="./static/images/sing3d.png" alt="teaser" style="width: 100%" />
            <!-- <video
              id="dollyzoom"
              autoplay
              controls
              muted
              loop
              playsinline
              width="100%">
              <source src="./static/videos/video.mp4" type="video/mp4" />
            </video> -->
          </div>
        </div>
      </div>
    </section>

    <!-- 摘要部分 -->
    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                In recent years, 3D generation has made great strides in both 
                academia and industry. However, generating 3D scenes from a single 
                RGB image remains a significant challenge, as current approaches 
                often struggle to ensure both object generation quality and scene 
                coherence in multi-object scenarios. To overcome these limitations, 
                we propose a novel three-stage framework for 3D scene generation with 
                explicit geometric representations and high-quality textural details 
                via single image-guided model generation and spatial layout optimization. 
                Our method begins with an image instance segmentation and inpainting phase, 
                which recovers missing details of occluded objects in the input images, 
                thereby achieving complete generation of foreground 3D assets. Subsequently, 
                our approach captures the spatial geometry of reference image by constructing 
                pseudo-stereo viewpoint for camera parameter estimation and scene depth inference, 
                while employing a model selection strategy to ensure optimal alignment between 
                the 3D assets generated in the previous step and the input. Finally, through 
                model parameterization and minimization of the Chamfer distance between point 
                clouds in 3D and 2D space, our approach optimizes layout parameters to produce 
                an explicit 3D scene representation that maintains precise alignment with input 
                guidance image. Extensive experiments on multi-object scene image sets have 
                demonstrated that our approach not only outperforms state-of-the-art methods 
                in terms of geometric accuracy and texture fidelity of individual generated 3D 
                models, but also has significant advantages in scene layout synthesis.
              </p>
            </div>
          </div>
        </div>
        <!--/ Abstract. -->
      </div>
    </section>

    <!-- Scripts Start -->
    <script type="module">
      import { ViewerModule } from "./modules/SceneViewer/scene-viewer.js";

      const viewer = new ViewerModule(
        ".scene-viewer",
        [
          "texed_0001",
          "texed_0002",
          "texed_0003",
          "texed_0004",
          "texed_0005",
          "texed_0006",
          "texed_0007",
          "texed_0008",
          "texed_0009",
          "texed_0010",
          "texed_0011",
        ],
        "https://huggingface.co/datasets/huanngzh/midi-page-assets/resolve/main/3d_models",
        "assets/images"
      );
      viewer.init();
    </script>
    <!-- Scripts End -->

    <section class="section" style="padding-top: 0">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <div class="has-text-centered">
              <h2 class="title is-3">Interactive Results</h2>
            </div>
            <br />
            <div class="scene-viewer">
              <!-- Scene Viewer -->
              <div id="loading-overlay">
                <div class="loading-spinner"></div>
              </div>
              <div id="viewer-container"></div>
              <div id="button-block"></div>
              <div class="swiper">
                <div class="swiper-button-prev"></div>
                <div class="swiper-button-next"></div>
                <div class="swiper-wrapper" id="image-slider"></div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- method overview -->
    <section class="section">
      <div class="container is-max-desktop">
        <div class="has-text-centered">
          <h2 class="title is-3">Method Overview</h2>
        </div>
        <br />
        <div class="columns is-centered">
          <div class="column is-full-width">
            <br />
            <img src="./static/images/overview.jpg" class="" alt="" />
            Our approach accomplishes complex scene generation through three collaborative subtasks. 
            Given a single image as guidance, during the Instance Segmentation and Generation stage, 
            we first perform object detection and instance segmentation to obtain instance-specific images, 
            masks, and related information. After that, we focuse on repairing imperfect instance images (e.g., bed) 
            and generates corresponding multiple 3D assets with generative model. In the Point Cloud Extraction stage, 
            we estimate camera parameters and depth maps of the input image to extract a complete scene point cloud, 
            which is further segmented using the previously obtained masks to derive independent point cloud representations 
            for each instance. Additionally, we sample the generated 3D models into point clouds and implement a 
            model selection strategy to choose 3D assets that best match the instance images. During layout optimization, 
            we optimize layout parameters by minimizing the 3D and 2D Chamfer Distance between the optimal model point cloud 
            (depicted in \textcolor{red}{red}) and the instance point cloud (depicted in \textcolor{green}{green}), 
            finally constructing a 3D scene that maintains high consistency with the reference image layout.
          </div>
        </div>
      </div>
    </section>

    <!-- citation -->
    <!-- <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="has-text-centered">
          <h2 class="title">BibTeX</h2>
        </div>
        <div
          class="columns is-centered has-text-centered"
          style="padding-bottom: 1.5rem">
          <div class="column is-four-fifths">
            <div class="content has-text-justified">
              <pre><code>@inproceedings{huang2025midi,
  title={Midi: Multi-instance diffusion for single image to 3d scene generation},
  author={Huang, Zehuan and Guo, Yuan-Chen and An, Xingqiao and Yang, Yunhan and Li, Yangguang and Zou, Zi-Xin and Liang, Ding and Liu, Xihui and Cao, Yan-Pei and Sheng, Lu},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={23646--23657},
  year={2025}
}</code></pre>
            </div>
          </div>
        </div>
      </div>
    </section> -->

    <!-- 结尾友链 -->
    <footer class="footer">
      <div class="container">
        <div class="content has-text-centered">
          <a class="icon-link" href="">
            <i class="fas fa-file-pdf"></i>
          </a>
          <a
            class="icon-link"
            href="https://github.com/xdlbw"
            class="external-link"
            disabled>
            <i class="fab fa-github"></i>
          </a>
        </div>
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p style="text-align: center">
                Source code of this page can be found at
                <a href="https://github.com/xdlbw/sing3d" target="_blank"
                  >sing3d</a
                >. The website template is borrowed from
                <a href="https://nerfies.github.io/" target="_blank">Nerfies</a
                >.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
